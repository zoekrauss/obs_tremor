{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a09c91f7-a06d-42da-95cc-fe7fe003ed6b",
   "metadata": {},
   "source": [
    "## Classify emergent detections from STA/LTA on the basis of waveform characteristics\n",
    "- runs in parallel over the list of detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed8da0ee-4b71-43a2-9e31-ff153937af44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import datetime\n",
    "import numpy as np\n",
    "import obspy\n",
    "from obspy.clients.fdsn.client import Client \n",
    "import obspy\n",
    "import pandas as pd\n",
    "import scipy.ndimage\n",
    "import geopy.distance\n",
    "import random\n",
    "client = Client('IRIS')\n",
    "import scipy\n",
    "import seaborn as sn\n",
    "import dask\n",
    "from dask.diagnostics import ProgressBar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747f11cf-3c7f-4951-808f-d0925a92eab7",
   "metadata": {},
   "source": [
    "## Pull in emergent detections from STA/LTA triggering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb46d47a-f951-4ff0-bf68-addcd7fa013e",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = 'YH'\n",
    "station = 'EBS3'\n",
    "channel = 'EH1'\n",
    "samp_rate = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f14fac5-9736-4fef-a1ca-516064f13da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For all:\n",
    "file_name='results/EBS3_2014_EH1_3-10Hz_triggering.pickle'\n",
    "with open(file_name,'rb') as handle:\n",
    "    detections = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6b9c799-6e3a-453b-95b1-70a12e01b6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the detections based on time, if desired!\n",
    "t1 = obspy.UTCDateTime(2015,2,1)\n",
    "t2 = obspy.UTCDateTime(2024,1,1)\n",
    "\n",
    "t_keep = [i for i,e in enumerate(detections) if (e[0]>t1) & (e[0]<t2)]\n",
    "detections = [detections[i] for i in t_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac5c18a-6c7b-4e3f-b539-e0c044a23a56",
   "metadata": {},
   "source": [
    "## Define classification functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8671ed3c-d40b-4788-b557-dce608f29630",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_peaks_welch(trace,sampling_rate,nperseg_multiple,microseism_cutoff=True):\n",
    "    \"\"\"\n",
    "    Estimate power spectra of a trace using Welch's method\n",
    "    Pick peaks within the spectra!\n",
    "    \n",
    "    INPUTS:\n",
    "    trace = obspy object, waveform\n",
    "    sampling_rate = sampling rate of trace\n",
    "    nperseg_multiple = length of each segment used to construct the Welch spectrum\n",
    "    microseism_cutoff = Bool, whether or not to cut off the lower end of the spectrum to avoid the microseism\n",
    "    \n",
    "    OUTPUTS:\n",
    "    f = frequencies of the spectra\n",
    "    Pxx_den = associated power at each frequency, in decibels\n",
    "    peak_ind = index of peaks within the spectra (f and Pxx_den), if found\n",
    "    peaks = picked peak object from scipy\n",
    "    median_power = median power of spectra from 20-80 Hz in decibels\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    fs = sampling_rate\n",
    "    x = trace.data\n",
    "    nperseg = fs * nperseg_multiple\n",
    "    \n",
    "    f,Pxx_den = scipy.signal.welch(x,fs,nperseg=nperseg)\n",
    "    if microseism_cutoff is True:\n",
    "        f = f[4:]\n",
    "        Pxx_den = Pxx_den[4:]\n",
    "        \n",
    "    Pxx_den = [10*np.log10(d) for d in Pxx_den]\n",
    "    median_power = np.median(Pxx_den[20:80])\n",
    "    \n",
    "    peaks = scipy.signal.find_peaks(Pxx_den,threshold =median_power*5,prominence=10) \n",
    "    peak_ind = peaks[0]\n",
    "    \n",
    "    return(f,Pxx_den,peak_ind,peaks,median_power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16351ccc-63a5-4c47-bef1-afdabd738f0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_gaussian(filtered_data,samp_rate,gaussian_width=5):\n",
    "    \"\"\"\n",
    "    Smooth waveform using a gaussian window\n",
    "    \n",
    "    INPUTS\n",
    "    filtered_data = filtered numpy array of seismic data (from an obspy trace)\n",
    "    samp_rate = sampling rate of data\n",
    "    gaussian width = width of Gaussian window in seconds\n",
    "    \n",
    "    OUTPUTS\n",
    "    smoothed_window = smoothed numpy array of seismic data\n",
    "    \"\"\"\n",
    "    \n",
    "    # Square data\n",
    "    data = filtered_data**2\n",
    "    \n",
    "    gaussian_radius = int((gaussian_width * samp_rate)/2)\n",
    "    smoothed_window=scipy.ndimage.gaussian_filter1d(data,sigma=gaussian_radius/4,radius=gaussian_radius)\n",
    "    \n",
    "    return smoothed_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7ca28da-a4a8-4081-a280-db6d3ef8b8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ship_noise_classifier(trace,sampling_rate):\n",
    "    \"\"\"\n",
    "    Check whether detection likely includes ship noise in the form of a spectral peak\n",
    "    \n",
    "    INPUTS\n",
    "    trace = obspy trace object\n",
    "    sampling_rate = sample rate of trace\n",
    "    \n",
    "    OUTPUTS\n",
    "    ship_classifier = number of peaks in the spectra. If any exist, ship noise is likely!\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Pick peaks on the smoothed spectrum of the trace (nperseg multiple = 1)\n",
    "    f,Pxx_den,peak_ind,peak_details,median_power = pick_peaks_welch(trace,sampling_rate,1,microseism_cutoff=True)\n",
    "    \n",
    "    if len(peak_ind)==0:\n",
    "        ship_classifier = 0\n",
    "    else:\n",
    "        ship_classifier = len(peak_ind)\n",
    "\n",
    "    \n",
    "    return ship_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196e1f3f-2de3-4a2e-a940-3c652d4dc28b",
   "metadata": {},
   "source": [
    "1. Calculate whether the detection likely includes ship noise (whether there are peaks in the Welch spectra)\n",
    "2. Perform 15 s Gaussian smoothing on filtered (4-15 Hz) waveform, calculate number of peaks with prominence > 0.1\n",
    "- 1 peak indicates T-phase, > 1 peak is consistent with tremor\n",
    "3. Calculate frequency ratio (ratio between power in 5-10 and 10-15 Hz) with 30 s padding on either side\n",
    "- Frequency ratio > 100 is consistent with tectonic tremor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c17d9622-f5c3-48ec-896d-d8db0e481620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_detection(t,network,station,channel,samp_rate,filepath):\n",
    "    \"\"\"\n",
    "    INPUTS \n",
    "    t = tuple of UTCDatetime, with on and off trigger time of detection\n",
    "    network = string\n",
    "    station = string\n",
    "    channel = string\n",
    "    samp_rate = sampling rate of channel\n",
    "    filepath = directory to save classification information to\n",
    "    \n",
    "    \n",
    "    OUTPUTS\n",
    "    Writes to file!\n",
    "    t = on and off times of detection\n",
    "    num_waveform_peaks = number of peaks with prominence > 0 in gaussian smoothed 4-15 Hz filtered waveform; more than 1 indicates a T-phase\n",
    "    ship_classifier = number of peaks in the Welch spectra, existence of peaks indicates ship noise\n",
    "    freq_ratio_welch = ratio between normalized decibels of Welch spectrum for 5-10 and 10-15 Hz. Values > 100 indicate tectonic tremor\n",
    "    max_amplitude = maximum amplitude of filtered waveform\n",
    "    \"\"\"\n",
    "    file_name = filepath +  station + '_' + str(t[0]).split('.')[0] + '.pickle'\n",
    "    if os.path.isfile(file_name)==True:\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        pad = 0\n",
    "        t1 = t[0]-pad\n",
    "        t2 = t[1]+pad\n",
    "\n",
    "        # Check whether there are peaks in the Welch spectra\n",
    "        # If ship_classifier > 0, indicates presence of ship noise\n",
    "        st1 = client.get_waveforms(network,station, \"*\",channel, t1-5, t2+5,attach_response=True);\n",
    "        st1.resample(samp_rate).merge(fill_value='interpolate')\n",
    "        st1[0].data = st1[0].data / st1[0].stats.response.instrument_sensitivity.value # Convert to m/s\n",
    "        st1.trim(starttime=t1,endtime=t2)\n",
    "        ship_classifier = ship_noise_classifier(st1[0],samp_rate)\n",
    "\n",
    "        # Get number of peaks in Gaussian-smoothed waveform\n",
    "        # If number of peaks = 1, indicates T-phase\n",
    "        st1 = client.get_waveforms(network,station, \"*\",channel, t1-5, t2+5,attach_response=True);\n",
    "        st1.resample(samp_rate).merge(fill_value='interpolate')\n",
    "        st1.filter('bandpass',freqmin=3,freqmax=10)\n",
    "        st1.remove_response()\n",
    "        st1.trim(starttime=t1,endtime=t2)\n",
    "        max_amplitude = np.max(np.abs(st1[0].data))\n",
    "        smoothed_window = apply_gaussian(st1[0].data,samp_rate,gaussian_width=15)\n",
    "        window_max = np.max(smoothed_window) # normalize window by its maximum\n",
    "        smoothed_window = [i/window_max for i in smoothed_window]\n",
    "        peaks = scipy.signal.find_peaks(smoothed_window,prominence=.1)\n",
    "        num_waveform_peaks=len(peaks[0])\n",
    "\n",
    "        # Calculate frequency ratio with 30 s padding on either side - using Welch\n",
    "        pad = 30\n",
    "        t1 = t[0]-pad\n",
    "        t2 = t[1]+pad\n",
    "        st2 = client.get_waveforms(network,station, \"*\",channel, t1-5, t2+5,attach_response=True);\n",
    "        st2.resample(samp_rate).merge(fill_value='interpolate')\n",
    "        st2[0].data = st2[0].data / st2[0].stats.response.instrument_sensitivity.value # Convert to m/s\n",
    "        st2.trim(starttime=t1,endtime=t2)\n",
    "        f,Pxx_den,peak_ind,peak_details,median_power = pick_peaks_welch(st2[0],samp_rate,5,microseism_cutoff=False)\n",
    "        normalized_power = Pxx_den\n",
    "        freq_ratio = 10**(np.median(normalized_power[25:50])/10)/10**(np.median(normalized_power[50:75])/10)\n",
    "        freq_ratio_welch=freq_ratio\n",
    "\n",
    "        # Write results to file\n",
    "        file_name = filepath +  station + '_' + str(t[0]).split('.')[0] + '.pickle'\n",
    "        with open(file_name, 'wb') as handle:\n",
    "                pickle.dump([t,station,num_waveform_peaks,ship_classifier,freq_ratio_welch,max_amplitude],handle)\n",
    "    \n",
    "    except:\n",
    "        didntwork = 1\n",
    "    \n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906abaec-6c6f-4a54-bb14-ea6df354a935",
   "metadata": {},
   "source": [
    "## Loop in parallel\n",
    "Note: simply overwrites files if they already exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5dec3e8-83f1-4c4b-8743-818b380be074",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'classifications/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d64979d0-f141-4cd5-963b-a347cf75f9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def loop_detections(t,network,station,channel,samp_rate,filepath):\n",
    "    return classify_detection(t,network,station,channel,samp_rate,filepath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72bda223-9b71-4029-9f7c-2c54f22df57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lazy_results = [loop_detections(t,network,station,channel,samp_rate,filepath) for t in detections]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "503e930b-9bfa-4694-9adf-a4e03cc007c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                                        ] | 2% Completed |  1min 27.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " WARNING (norm_resp): computed and reported sensitivities differ by more than 5 percent. \n",
      "\t Execution continuing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[#########                               ] | 24% Completed | 13min 47.4s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " WARNING (norm_resp): computed and reported sensitivities differ by more than 5 percent. \n",
      "\t Execution continuing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[################################        ] | 81% Completed | 46min 24.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " WARNING (norm_resp): computed and reported sensitivities differ by more than 5 percent. \n",
      "\t Execution continuing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[#################################       ] | 82% Completed | 47min 10.5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " WARNING (norm_resp): computed and reported sensitivities differ by more than 5 percent. \n",
      "\t Execution continuing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[#################################       ] | 83% Completed | 47min 25.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " WARNING (norm_resp): computed and reported sensitivities differ by more than 5 percent. \n",
      "\t Execution continuing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[####################################    ] | 90% Completed | 51min 27.5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " WARNING (norm_resp): computed and reported sensitivities differ by more than 5 percent. \n",
      "\t Execution continuing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[####################################### ] | 97% Completed | 55min  8.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " WARNING (norm_resp): computed and reported sensitivities differ by more than 5 percent. \n",
      "\t Execution continuing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[####################################### ] | 98% Completed | 55min 21.3s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " WARNING (norm_resp): computed and reported sensitivities differ by more than 5 percent. \n",
      "\t Execution continuing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 56min 13.3s\n"
     ]
    }
   ],
   "source": [
    "with ProgressBar():\n",
    "    results = dask.compute(lazy_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a8934a-c800-4673-8424-a2d7068d41ba",
   "metadata": {},
   "source": [
    "## Pull in all saved files of classifications and save to one pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "178c3cbd-b7bf-4498-b6cd-73e680d2123b",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(filepath+station+'*')\n",
    "\n",
    "classifications = []\n",
    "for f in files:\n",
    "    with open(f,'rb') as handle:\n",
    "        classi = pickle.load(handle)\n",
    "        classifications.append(classi)\n",
    "        \n",
    "# Sort!\n",
    "times = [c[0][0] for c in classifications]\n",
    "sort_ind = np.argsort(times)\n",
    "classifications = [classifications[i] for i in sort_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33c471a8-35ef-4808-9d77-2ebf3910b167",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write all to pickle\n",
    "file_name = 'EBS3_EH1_3-10Hz_classifications_new.pickle'\n",
    "pickle.dump(classifications,open(file_name,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21800738-f161-40e6-882b-8de7af710136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12314"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(classifications)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alaska-ml",
   "language": "python",
   "name": "alaska-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
